---
title: Vacations
author: ''
date: '2020-02-29'
slug: vacations
categories: []
tags: []
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>My partner and I have plans to travel the world some day. But, after talking about the places that we would want to go visit, I realized that we had one obvious problem: our preferences were different. I am quite the nerd. Over the years, I’ve watched hundreds of episodes of various Anime series and read tens of Sci-Fiction novels. As a result, I very much want to visit bustling and futuristic East Asian metropoleis like Seoul and Tokyo. My partner, however, has always been fascinated with the Continent. She wants to experience, first hand, how the Rwandan people survived and moved past the horror of their history. She would like to journey across the Safari, and learn from the cultures of indigeous peoples still living the way their ancestors have for thousands of years.</p>
<p>Unfortunately, money don’t grow on trees.</p>
<p>We probably won’t be able to visit every single place that we each individually would want to visit. Unless one of us (or better yet both) sells our soul in exchange for affordable health care and copious paid vacation time off, it is unlikely we will have the financial means nor time to visit everywhere anytime soon. I realized then that this is just an optimization problem. The question is: How can my partner and I maximize our total utility (visit the places we both want to visit the most) given the constraints of resources like time and money? There is only one answer: DATA (pronounced with a German accent).</p>
<p>I figured that if my partner and I ranked the places we wanted to visit with our preferences, we could use characteristics about those places to determine where to go next!</p>
</div>
<div id="data-scraping" class="section level2">
<h2>Data Scraping</h2>
<p>First, I needed to find a dataset that had lots of cities and some revelant data or metrics on those cities. After some google searches, I found a website called <a href="https://www.numbeo.com/" class="uri">https://www.numbeo.com/</a>. Numbeo is self-described as the world’s largest database of user contributed data about cities and countries worldwide. I don’t know if that’s true but it had rankings and indices on cost of living, housing indicators, health care, traffic, crime, pollution, etc, which was perfect for what I was trying to do.</p>
<p>I used the SelectorGadget and the r package “rvest”. The selector tool enabled me to point and click CSS selectors on the page, and then reference them in my code. This tool can be found here. <a href="https://selectorgadget.com/" class="uri">https://selectorgadget.com/</a>. At first, I was a bit stuck. Sometimes, the tool would give me the right css selector for one column of a table, but not the next. But then I realized that on each page, the css selector was the same. So, I could just iterate over the table using a for loop and automate the whole process.</p>
<p>Below is code that interates over the Numbeo cost of living webpage for the Africa region.</p>
<pre class="r"><code>url &lt;- &#39;https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2019-mid&amp;region=002&#39;

#Reading the HTML code from the website

web &lt;- read_html(url)
data = vector(mode = &quot;list&quot;, 6)
x = 1
c = &#39;td:nth-child(&#39; 
b = &#39;)&#39;
a = 3
f = paste(c,a,b)
for(i in c(3:8)){
  #Using CSS selectors to scrape
  
  table &lt;- html_nodes(web,paste(c,i,b))
  
  #Converting the data to numeric
  table_data &lt;- as.numeric(html_text(table))
  data[[x]] = table_data
  x = x + 1;
}
#Scraping city names
names &lt;- html_nodes(web,&#39;.cityOrCountryInIndicesTable&#39;)

names_data &lt;- html_text(names)

dataframe = data.frame(name = c(names_data), cost_of_living = c(data[[1]]),rent = c(data[[2]]), col_plus_rent = c(data[[3]]), 
                  grocery = c(data[[4]]), rest = c(data[[5]]), pow_pur_ind = c(data[[6]]), region = &quot;Africa&quot;)</code></pre>
<p>Here is some code displaying just the first three observations.</p>
<pre class="r"><code>dataframe %&gt;% 
  as_tibble() %&gt;% 
  head(n=3)</code></pre>
<pre><code>## # A tibble: 3 x 8
##   name       cost_of_living  rent col_plus_rent grocery  rest pow_pur_ind region
##   &lt;fct&gt;               &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt; 
## 1 Harare, Z…           59.2  13.8          37.5    53.4  42.3        27.0 Africa
## 2 Pretoria,…           49.2  16.2          33.4    35.2  42.8        81.9 Africa
## 3 Johannesb…           47.4  17.9          33.3    37.2  45.8        79.1 Africa</code></pre>
<p>For regions, Europe, Africa, and Asia, I repeat this process, scraping data on metrics spanning: cost of living, pollution, and crime. I could have scraped this data directly from the main page for each metric, but that would have just given me the city and country, not the region. I would have had to do extra work to figure out which city was in which region.</p>
</div>
<div id="manipulating-cities-data" class="section level2">
<h2>Manipulating Cities Data</h2>
<p>I now had nine dataframes: one per region per metric. And I wanted to combine them all together so I would have one dataframe. Using a left_join one at a time, I merged the pollution and crime dataframes into the dataframe containing the cost of living dataframe. To avoid double counting the column region, I passed into the select method -c(region).</p>
<p>Now, the dataframe, africa, has all the variables and observations from each of the three africa datasets. NA’s have filled in cells where city data does not exist for that metric.</p>
<pre class="r"><code>africa_vac &lt;- left_join(africa_vac, select (africa_vac_poll, -c(region)), by= &quot;name&quot;)
africa &lt;- left_join(africa_vac, select (africa_vac_crime, -c(region)), by= &quot;name&quot;)
names(africa)</code></pre>
<pre><code>##  [1] &quot;name&quot;           &quot;cost_of_living&quot; &quot;rent&quot;           &quot;col_plus_rent&quot; 
##  [5] &quot;grocery&quot;        &quot;rest&quot;           &quot;pow_pur_ind&quot;    &quot;region&quot;        
##  [9] &quot;poll_ind&quot;       &quot;poll_exp&quot;       &quot;crime&quot;          &quot;safety&quot;</code></pre>
<p>I used that process for each region until I had three complete dataframes, and the used the method rbind() to put them all together.</p>
<pre class="r"><code>vacation_data &lt;- rbind(africa, asia, europe)</code></pre>
<p>Here is a few randomly generated observations from the vacation_data dataframe.</p>
<pre class="r"><code>ind &lt;- sample(dim(vacation_data)[1],4, replace = FALSE, prob = NULL)
as_tibble(vacation_data[ind,])</code></pre>
<pre><code>## # A tibble: 4 x 12
##   name  cost_of_living  rent col_plus_rent grocery  rest pow_pur_ind region
##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt; 
## 1 Delh…           28.3  8.52          18.9    26.4  24.0        62.3 Asia  
## 2 Izhe…           34.0  6.9           21.1    29.0  30.0        41.0 Europe
## 3 Yere…           33.1 10.6           22.3    25.4  32.2        30.7 Asia  
## 4 Bonn…           67.5 28.2           48.7    50.9  62.0       111.  Europe
## # … with 4 more variables: poll_ind &lt;dbl&gt;, poll_exp &lt;dbl&gt;, crime &lt;dbl&gt;,
## #   safety &lt;dbl&gt;</code></pre>
<p>There are currently over 200 something cities in the complete data frame, many of which, my partner nor I have ever heard of. It felt odd rating a city that we knew nothing about. I anticipated that we would rate it very low (what could we be excited about?) or just rate it based on the country that it is in. This would, I hypothesized, skew up our preference towards cities that are more well known and deflate the ratings of unknown cities. Besides that, it would also take us long time to rate properly–going down a list of cities one at a time. To fix this problem, I split the name column into two columns: city and country using a tidyr method called seperate(). Now a factor, there are only 84 levels for the country variable, much more managable to rate.</p>
<pre class="r"><code>vacation_data &lt;- vacation_data %&gt;% 
  separate(name, c(&quot;city&quot;, &quot;country&quot;), sep = &quot;,&quot;) %&gt;%
  mutate(country = as.factor(country))
length(levels(vacation_data$country))</code></pre>
<pre><code>## [1] 84</code></pre>
</div>
<div id="getting-preferences" class="section level2">
<h2>Getting Preferences</h2>
<p>To make preference collection more user-friendy, I selected just levels of the country variable from vacation_data into a tibble and exported it as a txt file for excel.</p>
<pre class="r"><code>countries &lt;- levels(vacation_data$country)
as_tibble(countries)</code></pre>
<pre><code>## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `tibble::enframe(name = NULL)` instead.
## This warning is displayed once per session.</code></pre>
<pre><code>## # A tibble: 84 x 1
##    value                    
##    &lt;chr&gt;                    
##  1 &quot; Albania&quot;               
##  2 &quot; Algeria&quot;               
##  3 &quot; Armenia&quot;               
##  4 &quot; Austria&quot;               
##  5 &quot; Azerbaijan&quot;            
##  6 &quot; Bahrain&quot;               
##  7 &quot; Bangladesh&quot;            
##  8 &quot; Belarus&quot;               
##  9 &quot; Belgium&quot;               
## 10 &quot; Bosnia And Herzegovina&quot;
## # … with 74 more rows</code></pre>
<pre class="r"><code>write.table(countries, &quot;vacations/countries.txt&quot;, sep=&quot;\t&quot;)</code></pre>
<p>After the txt file was filed out by hand in the most professional manner possible, I then imported back into my workspace as a csv file. Once again, I used left join to join the two dataframes together. Perfecto!</p>
<pre class="r"><code>vacation_pref &lt;- read.csv(&quot;vacations/vacation_pref.csv&quot;, sep=&quot;,&quot;)
vacation_data &lt;- left_join(vacation_data, vacation_pref, by= &quot;country&quot;)</code></pre>
<pre class="r"><code>vacation_data &lt;- vacation_data %&gt;%
  mutate(comb = naomi + cam) </code></pre>
</div>
<div id="data-visualization" class="section level2">
<h2>Data Visualization</h2>
<p>Whew, that was a lot of work! But now comes the cool part. Visualizing and understanding what the data means for my partner and I. And finally answering the question that we have been waiting for…where do we go from here?</p>
<p>Well, the easiest question to start with is how did our preferences vary. From the two bar charts, produced using ggplot2’s geom_bar(), it seems that the data provides evidence to support my initial hypothesis that Naomi wants to travel to Africa the most. Namely, it apepars that Naomi, on average, ranked countries in Africa the highest. But what is also interesting is that there seems to be evidence that I am much more impartial when ranking countries between regions. In other words, although the region Asia had the highest average preference score, that does guruantee that a significant difference in preference between the other regions exists. On average, the error bars (+/- one standard deviation) for that region include the means of other regions.
<img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-11-1.png" width="672" /><img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<p>Next, I wanted to look at another bar chart that shows the combined mean preference score grouped by region. “Tsamina mina eh eh, Waka waka eh ehhe!” The region Africa has the highest combined mean preference score for the countries ranked from that region, which indicates that we should priorize region Africa when planning our future trips. I will note however that the upped end of the error bar for the region Asia extends just a bit beyond the error bar for Africa, suggesting that preference for Asia could potentially be above Africa. Nevertheless, we will work with the Africa region for the next part.</p>
<p><img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now that we have a region. Where in that region is the best place to go? Well, I decided to make a graph that is definitely pushing up against the limits of TMI (too much information), but I wanted to showcase my skills! We have safety on the x axis and cost of living on the y axis. Obviously, the higher up on the safety index a city is, the more safe it is. That is quite intuitive for the viewer (you); however, for the cost of living index, I wanted make sure that that metric is displayed accurately. The higher up on the cost of living index, the more expensive the city, so I reversed the axis so that the upper right hand corner is where the most desirable cities will be. Dashed lines drawing the quandrants are supposed help the viewer see this trend. Next, the metrics, combined preference and pollution index, are displayed by color and size, respectively. The lighter the coordinate point, the higher the combinded preference for that city; the larger the size of that point, the more polluted that city.</p>
<p>From this data, it appears that cities in North Africa (Tunis, Algiers, Cairo, Alexandra, Casablanca) have the lowest cost of living and arer the highest on the safety index in the region Africa, pollution being relatively similar between cities. Which cities do we prefer the most? Cairo and Alexandra (Egypt) have much lighter colors than the others, and so, appear to be the prefered destination for the both of us. It looks like we are headed to the Pyramids!</p>
<p><img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>A lot this worked out better than I thought that it would. Still, I’m sure that there are things that I could have done better or more efficiently. One issue is that Numbeo, where I got the city data, didn’t have as much data on Africa and Asia as it did Europe (just check out that graph).
<img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>So that is a bit of a bummer. Another issue is that the preference/ranking could have been more scientific. I went down the list of an excel spreadsheet calling out country names to a tired Naomi, who seemed to only rank cities with a 1 or a 7 (see below).
<img src="/post/2020-02-29-vacations_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Besides that I am quite happy. This is literally all my work, and I am proud of what I made. I feel like Naruto after he finally mastered the rasengan.</p>
</div>
